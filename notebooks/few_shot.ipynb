{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from functools import cache\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "from torchvision.transforms import functional as F, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.datasets.coco_org import Coco2017Dataset\n",
    "from src.models.image_encoder import get_image_embedding_module\n",
    "from src.models.text_encoder import get_text_embedding_module\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "plt.style.use('seaborn-v0_8-bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "image_model = get_image_embedding_module(\"beit\", device=device)\n",
    "text_model = get_text_embedding_module(\"clip\", device=device)\n",
    "print(f\"Using device {device}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.abspath(\n",
    "    \"/Users/xihaochen/Documents/National University of Singapore/Modules/2223 Sem 2/CP4101 B. Comp. Dissertation/Project/main-project\")\n",
    "\n",
    "SAVE_DIR = os.path.join(PROJECT_DIR, \"checkpoints\")\n",
    "\n",
    "COCO_DIR = os.path.abspath(\n",
    "    \"/Users/xihaochen/Documents/National University of Singapore/Modules/2223 Sem 2/CP4101 B. Comp. Dissertation/Project/coco-org/coco2017\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coco = Coco2017Dataset(COCO_DIR)\n",
    "dataset = coco.dataframe\n",
    "target_classes = coco.topics\n",
    "dataset = dataset.explode(\"labels\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb.fit(dataset[\"labels\"].tolist())\n",
    "lb.classes_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_k_samples_per_class(df: pd.DataFrame, k: int, seed: int = 42) -> pd.DataFrame:\n",
    "    print(f\"Sampling {k} points per concept\")\n",
    "    _samples = []\n",
    "    for _concept in target_classes:\n",
    "        _data = df[df[\"labels\"] == _concept]\n",
    "        _samples.append(_data.sample(n=k, replace=len(_data) < k, random_state=seed))\n",
    "\n",
    "    _returned_df = pd.concat(_samples, axis=0)\n",
    "    _returned_df.reset_index(inplace=True)\n",
    "    return _returned_df\n",
    "\n",
    "\n",
    "img_resize = transforms.Resize((224, 224))\n",
    "\n",
    "\n",
    "@cache\n",
    "def process_image(path: str) -> np.ndarray:\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    image = F.pil_to_tensor(image)\n",
    "    image = img_resize(image).float()\n",
    "    encoded = image_model(image).cpu().numpy()\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def convert_image_to_X_y(data: pd.DataFrame, show_progress=False) -> tuple[np.ndarray, np.ndarray]:\n",
    "    all_images = list()\n",
    "    all_labels = data[\"labels\"].tolist()\n",
    "    # all_labels = lb.transform(all_labels)\n",
    "\n",
    "    iter = data.iterrows()\n",
    "    if show_progress:\n",
    "        iter = tqdm(iter, total=len(data))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, row in iter:\n",
    "            encoded = process_image(row[\"filepath\"])\n",
    "            all_images.append(encoded)\n",
    "\n",
    "    all_images = np.vstack(all_images)\n",
    "    return all_images, all_labels\n",
    "\n",
    "\n",
    "@cache\n",
    "def process_text(text) -> np.ndarray:\n",
    "    return text_model(text).cpu().numpy()\n",
    "\n",
    "\n",
    "def convert_text_to_X_y(data: pd.DataFrame, show_progress=False) -> tuple[np.ndarray, np.ndarray]:\n",
    "    all_text = list()\n",
    "    all_labels = data[\"labels\"].tolist()\n",
    "    # all_labels = lb.transform(all_labels)\n",
    "\n",
    "    iter = data.iterrows()\n",
    "    if show_progress:\n",
    "        iter = tqdm(iter, total=len(data))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, row in iter:\n",
    "            encoded = process_text(row[\"text\"])\n",
    "            all_text.append(encoded)\n",
    "\n",
    "    all_text = np.vstack(all_text)\n",
    "    return all_text, all_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(dataset, train_size=0.6, random_state=42)\n",
    "test_df = get_k_samples_per_class(test_df, 50, seed=42)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_image_features, test_image_labels = convert_image_to_X_y(test_df, show_progress=True)\n",
    "test_text_features, test_text_labels = convert_text_to_X_y(test_df, show_progress=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.array(test_image_labels).shape, np.array(test_text_labels).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert np.array_equal(test_image_labels, test_text_labels), \"Labels are not the same\"\n",
    "test_labels = test_image_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def few_shot(ks, all_train_df, print_results=True, show_sample_progress=False):\n",
    "    _best_params = {}\n",
    "    _reports_str = {}\n",
    "    _reports_dict = {}\n",
    "\n",
    "    print(f\"ks:{ks.tolist()}\")\n",
    "    for k in tqdm(ks, desc=\"k\"):\n",
    "        _best_params[k] = {}\n",
    "        _reports_str[k] = {}\n",
    "        _reports_dict[k] = {}\n",
    "\n",
    "        if k < 5:\n",
    "            _image_classifier = LogisticRegression(verbose=False, max_iter=10_000, multi_class=\"ovr\")\n",
    "            _text_classifier = LogisticRegression(verbose=False, max_iter=10_000, multi_class=\"ovr\")\n",
    "        else:\n",
    "            _image_classifier = BayesSearchCV(\n",
    "                LogisticRegression(verbose=False, max_iter=100_000, multi_class=\"ovr\"),\n",
    "                {\n",
    "                    \"C\": Real(1e-6, 1e+6, prior=\"log-uniform\"),\n",
    "                },\n",
    "                n_jobs=-1, verbose=0\n",
    "            )\n",
    "            _text_classifier = BayesSearchCV(\n",
    "                LogisticRegression(verbose=False, max_iter=100_000, multi_class=\"ovr\"),\n",
    "                {\n",
    "                    \"C\": Real(1e-6, 1e+6, prior=\"log-uniform\"),\n",
    "                },\n",
    "                n_jobs=-1, verbose=0\n",
    "            )\n",
    "\n",
    "        _samples = get_k_samples_per_class(all_train_df, k)\n",
    "        _train_image_features, _train_image_labels = convert_image_to_X_y(_samples, show_progress=show_sample_progress)\n",
    "        _train_text_features, _train_text_labels = convert_text_to_X_y(_samples, show_progress=show_sample_progress)\n",
    "        print(\"Encoded all images and texts\")\n",
    "\n",
    "        \"\"\"TRAIN IMAGE CLASSIFIER\"\"\"\n",
    "        _image_scalar = StandardScaler()\n",
    "        _train_image_features_scaled = _image_scalar.fit_transform(_train_image_features)\n",
    "        _test_image_features_scaled = _image_scalar.transform(test_image_features)\n",
    "\n",
    "        print(\"Training image classifier\")\n",
    "        _image_classifier.fit(_train_image_features_scaled, _train_image_labels)\n",
    "        print(\"Done training image classifier\")\n",
    "\n",
    "        _best_params[k][\"image\"] = _image_classifier.get_params(deep=True)\n",
    "\n",
    "        _image_pred = _image_classifier.predict(_test_image_features_scaled)\n",
    "        _reports_str[k][\"image\"] = classification_report(test_image_labels, _image_pred, zero_division=1)\n",
    "        _reports_dict[k][\"image\"] = classification_report(test_image_labels, _image_pred, output_dict=True, zero_division=1)\n",
    "\n",
    "        \"\"\"TRAIN TEXT CLASSIFIER\"\"\"\n",
    "        _text_scalar = StandardScaler()\n",
    "        _train_text_features_scaled = _text_scalar.fit_transform(_train_text_features)\n",
    "        _test_text_features_scaled = _text_scalar.transform(test_text_features)\n",
    "\n",
    "        print(\"Training text classifier\")\n",
    "        _text_classifier.fit(_train_text_features_scaled, _train_text_labels)\n",
    "        print(\"Done training text classifier\")\n",
    "\n",
    "        _best_params[k][\"text\"] = _text_classifier.get_params(deep=True)\n",
    "\n",
    "        _text_pred = _text_classifier.predict(_test_text_features_scaled)\n",
    "        _reports_str[k][\"text\"] = classification_report(test_text_labels, _text_pred, zero_division=1)\n",
    "        _reports_dict[k][\"text\"] = classification_report(test_text_labels, _text_pred, output_dict=True, zero_division=1)\n",
    "\n",
    "        \"\"\"GET CROSS MODAL PREDICTION\"\"\"\n",
    "        _image_pred = lb.transform(_image_pred)\n",
    "        _text_pred = lb.transform(_text_pred)\n",
    "        _cross_pred = np.multiply(np.array(_image_pred), np.array(_text_pred))\n",
    "        _cross_pred = lb.inverse_transform(_cross_pred)\n",
    "        _reports_str[k][\"cross\"] = classification_report(test_labels, _cross_pred, zero_division=1)\n",
    "        _reports_dict[k][\"cross\"] = classification_report(test_labels, _cross_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "        if print_results:\n",
    "            print(f\"\\nk={k}\")\n",
    "            for key in (\"image\", \"text\", \"cross\"):\n",
    "                print(f\"{key.upper()}\")\n",
    "                print(_reports_str[k][key])\n",
    "\n",
    "        torch.save({\n",
    "            \"best_params\": _best_params,\n",
    "            \"reports_str\": _reports_str,\n",
    "            \"reports_dict\": _reports_dict,\n",
    "        }, os.path.join(SAVE_DIR, f\"few_shot_results-bayes-{k}.pt\"))\n",
    "\n",
    "    return _best_params, _reports_str, _reports_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# best_params, reports_str, reports_dict = few_shot(2 ** np.arange(0, 1), train_df, print_results=False, show_sample_progress=False)  # test\n",
    "best_params, reports_str, reports_dict = few_shot(2 ** np.arange(0, 8), train_df, print_results=False)  # run\n",
    "# best_params, reports_str, reports_dict = few_shot(2 ** np.arange(, 8), train_df, print_results=False)  # run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " for k, reports in sorted(reports_str.items()):\n",
    "    print(\"=\" * 20)\n",
    "    print(f\"k={k}\")\n",
    "    for task, report in reports.items():\n",
    "        print(f\"{task.upper()}\")\n",
    "        print(report)\n",
    "        print(\"=\" * 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_dir = os.path.abspath(\n",
    "    \"/Users/xihaochen/Documents/National University of Singapore/Modules/2223 Sem 2/CP4101 B. Comp. Dissertation/Project/main-project/notebooks/plots\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ks = 2 ** np.arange(0, 8)\n",
    "results_i2i = np.array([20, 29, 36, 39, 43, 46, 44, 47]) / 100\n",
    "results_t2t = np.array([41, 46, 53, 56, 57, 57, 59, 59]) / 100\n",
    "results_i2t = np.array([39, 43, 45, 49, 54, 55, 53, 57]) / 100\n",
    "results_t2i = np.array([37, 39, 44, 49, 53, 54, 52, 54]) / 100\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "titles = [\n",
    "    [\"Image-to-Image\", \"Text-to-Text\"],\n",
    "    [\"Image-to-Text\", \"Text-to-Image\"]\n",
    "]\n",
    "y_lims = [\n",
    "    [[0.201, 0.591], [0.379, 1.05]],\n",
    "    [[0.359, 0.691], [0.349, 0.691]]  # TODO\n",
    "]\n",
    "fs_scores = [\n",
    "    [results_i2i, results_t2t],\n",
    "    [results_i2t, results_t2i]  # TODO\n",
    "]\n",
    "full_scores = [\n",
    "    [[0.563, (120, 0.560)], [0.999, (120, 0.989)]],\n",
    "    [[0.664, (120, 0.660)], [0.662, (120, 0.660)]]  # TODO\n",
    "]\n",
    "\n",
    "for r, row in enumerate(ax):\n",
    "    for c, curr_ax in enumerate(row):\n",
    "        curr_ax.plot(ks, fs_scores[r][c], label=titles[r][c], marker=\"x\", color=\"tab:cyan\")\n",
    "        curr_ax.axhline(y=full_scores[r][c][0], linestyle=\"dashed\", label=\"All data\", color=\"tab:red\")\n",
    "        curr_ax.text(full_scores[r][c][1][0], full_scores[r][c][1][1], full_scores[r][c][0], horizontalalignment='right', verticalalignment='top',\n",
    "                     color=\"tab:red\", fontsize=10)\n",
    "        curr_ax.set_xticks(ks)\n",
    "        curr_ax.set_xticklabels(ks, rotation=45, horizontalalignment=\"center\", fontsize=8)\n",
    "        curr_ax.set_xlabel(\"S (no. of samples per concept)\", fontsize=8)\n",
    "        curr_ax.set_ylabel(\"MAP score\", fontsize=8)\n",
    "        curr_ax.set_title(titles[r][c], fontsize=10)\n",
    "        curr_ax.legend(loc=\"lower right\", fontsize=8)\n",
    "        curr_ax.grid(which=\"major\")\n",
    "        curr_ax.set_ylim(y_lims[r][c])\n",
    "\n",
    "fig.tight_layout(pad=1.5)\n",
    "plt.subplots_adjust(top=0.92)\n",
    "fig.suptitle(\"MAP few-shot trends on test set\", fontsize=12)\n",
    "plt.savefig(os.path.join(plot_dir, \"few-shot-all-trends.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ks = 2 ** np.arange(0, 8)\n",
    "durations = np.array([5, 535, 1729, 3048, 5841, 11615, 21762, 61167]) / 1000\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ks, durations, label=\"Time to train (1000 sec)\", marker=\"^\", color=\"tab:green\")\n",
    "plt.xticks(ks, rotation=45, horizontalalignment=\"center\")\n",
    "plt.xlabel(\"S (no. of samples per concept)\")\n",
    "plt.ylabel(\"Time (1000 sec)\")\n",
    "plt.grid(which=\"major\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Average time taken to train\")\n",
    "plt.savefig(os.path.join(plot_dir, \"few-shot-timed.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ks = 2 ** np.arange(0, 8)\n",
    "results_dict = torch.load(\n",
    "    \"/Users/xihaochen/Documents/National University of Singapore/Modules/2223 Sem 2/CP4101 B. Comp. Dissertation/Project/main-project/checkpoints/few_shot_results-bayes-128.pt\")\n",
    "results_dict.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.around([results_dict[\"reports_dict\"][k][\"image\"][\"weighted avg\"][\"precision\"] for k in ks], decimals=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.around([results_dict[\"reports_dict\"][k][\"text\"][\"weighted avg\"][\"precision\"] for k in ks], decimals=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.around([results_dict[\"reports_dict\"][k][\"cross\"][\"weighted avg\"][\"precision\"] for k in ks], decimals=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
